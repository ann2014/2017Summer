---
title: "Project 3 - Data 643"
author: "Ann Liu-Ferrara"
date: "June 21, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## singular value decomposition (SVD) 

SVD builds features that may or may not map neatly to items (such as movie genres or news topics). As in many areas of machine learning, the lack of explainability can be an issue).

SVD requires that there are no missing values. There are various ways to handle this, including (1) imputation of missing values, (2) mean-centering values around 0, or (3) <advanced> using a more advance technique, such as stochastic gradient descent to simulate SVD in populating the factored matrices.

Calculating the SVD matrices can be computationally expensive, although calculating ratings once the factorization is completed is very fast. You may need to create a subset of your data for SVD calculations to be successfully performed, especially on a machine with a small RAM footprint.

# Modeling using SVDApproximation library

```{r}
library(data.table)
library(devtools)
if("SVDApproximation" %in% rownames(installed.packages()) == FALSE){
  install_github(repo = "SVDApproximation", username = "tarashnot")
}
library(SVDApproximation)

dim(ratings)
head(ratings)
summary(ratings)
visualize_ratings(ratings_table = ratings)

set.seed(1)
mtx <- split_ratings(ratings_table = ratings, 
                     proportion = c(0.7, 0.15, 0.15))

model <- svd_build(mtx)

model_tunes <- svd_tune(model, r = 2:50)

model_tunes$train_vs_valid

rmse_svd <- svd_rmse(model, r = model_tunes$r_best, rmse_type = c("test"))
rmse_svd

```

# Alternating Least Squares (ALS)

```{r}
if("recommenderlab" %in% rownames(installed.packages()) == FALSE){
  install_github("mhahsler/recommenderlab")
}
library(recommenderlab)
library(ggplot2)

# binary data random sample from anonymous web click-stream data from microsoft.com
data("MSWeb")

# only select users click more than 5 items
MSWeb5 <- MSWeb[rowCounts(MSWeb) > 5, ]
MSWeb5
as(MSWeb5[1:2], 'list')
hist(rowCounts(MSWeb5), breaks = 20)
hist(colCounts(MSWeb5), breaks = 25)

# popularity of the data
image(sample(MSWeb5, 200))
plot(results, annotate=c(1,3), legend="topleft")
qplot(rowSums(MSWeb5)) + stat_bin(binwidth = 5) +
  geom_vline(xintercept = mean(rowCounts(MSWeb5)), col = "red", linetype = 'dashed') +
  ggtitle ("Distribution of clicks by user")

# split data
which_train <- sample(x = c(TRUE, FALSE), size = nrow(MSWeb5), replace = TRUE, prob = c(0.8, 0.2))
recc_data_train <- MSWeb5[which_train, ]
recc_data_test <- MSWeb5[!which_train, ]

rec <- Recommender(recc_data_train, method = "ALS", parameter = list(lambda=0.1, n_factors=10, 
                                  n_iterations=10, seed = NULL, verbose = FALSE)) 
model_details <- getModel(rec)

# predict 6 items to each of the users in test data set
recom <- predict(rec, recc_data_test, n = 5)
recom
recc_matrix <- sapply(recom@items, function(x) {
  colnames(MSWeb5)[x]
})
recc_matrix[, 1:4]

eval_sets <- evaluationScheme(data = MSWeb5, method="cross", k = 4, given = 5, goodRating <- 1)
eval_reco <- Recommender(data = getData(eval_sets, 'train'), method = 'ALS', parameter = NULL)
eval_prediction <- predict(object = eval_reco, newdata = recc_data_test)

# accuracy_table <- function(scheme, algorithm, parameter){
#   als <- Recommender(getData(scheme, "train"), algorithm, parameter = parameter)
#   p <- predict(als, getData(scheme, "known"), type="ratings")                      
#   acc_list <- calcPredictionAccuracy(p, getData(scheme, "unknown"))
#   total_list <- c(algorithm =algorithm, acc_list)
#   total_list <- total_list[sapply(total_list, function(x) !is.null(x))]
#   return(data.frame(as.list(total_list)))
# }
# 
# table_ALS_1 <- accuracy_table(scheme, algorithm = "ALS", 
#                   parameter = list(lambda=0.1, n_factors=200, 
#                   n_iterations=10, seed = 1234, verbose = TRUE))
# 
# rbind(table_random, table_pop, table_ubcf, table_ibcf, table_ALS_1)


```


# Summary of findings and recommendations

I learned 2 recommender system algorithms in this project SVD and ALS, some results of the models were compared. 


# Reference:

http://www.infofarm.be/articles/alternating-least-squares-algorithm-recommenderlab

https://rpubs.com/tarashnot/recommender_comparison

https://www.r-bloggers.com/recosystem-recommender-system-using-parallel-matrix-factorization/


https://ashokharnal.wordpress.com/2014/12/18/using-recommenderlab-for-predicting-ratings-for-movielens-data/

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.168.213&rep=rep1&type=pdf

https://rpubs.com/waltw/285262