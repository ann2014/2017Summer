---
title: "Project 2 - Data 643"
author: "Ann Liu-Ferrara"
date: "June 12, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Content-Based and Collaborative Filtering

Using data ratings from library SVDApproximation, there are 1M ratings with 6040 users and 3706 movies. The ratings are 1-5 (stars).

```{r}
library(recommenderlab)
library(SVDApproximation)
library(devtools)
install_github(repo = "SVDApproximation", username = "tarashnot")
library(SVDApproximation)

dim(ratings)
head(ratings)
summary(ratings)
visualize_ratings(ratings_table = ratings)


```

# Content-Based

```{r}
# computer item average as missing value
sparse_ratings <- sparseMatrix(i = ratings$user, j = ratings$item, x = ratings$rating, 
                               dims = c(length(unique(ratings$user)), length(unique(ratings$item))),  
                               dimnames = list(paste("u", 1:length(unique(ratings$user)), sep = ""), 
                                               paste("m", 1:length(unique(ratings$item)), sep = "")))
sparse_ratings[1:10, 1:10]

(real_ratings <- new("realRatingMatrix", data = sparse_ratings))


# create a Recommender model
model <- Recommender(real_ratings, method = "POPULAR", param=list(normalize = "center"))

# prediction of missing values for first 7 users using item average
prediction <- predict(model, real_ratings[1:7], type="ratings")
(as(prediction, "matrix")[,1:7])

# model evaluation
# 5 ratings of 20% of users are excluded for testing
set.seed(1)
e <- evaluationScheme(real_ratings, method="split", train=0.8, given=-7)

model <- Recommender(getData(e, "train"), "POPULAR")
prediction <- predict(model, getData(e, "known"), type="ratings")

rmse_popular <- calcPredictionAccuracy(prediction, getData(e, "unknown"))[1]
rmse_popular


```

# User-User Collaborative Filtering


```{r}
#Building model
model <- Recommender(real_ratings, method = "UBCF", 
                     param=list(normalize = "center", method="Cosine", nn=50))

#Making predictions 
prediction <- predict(model, real_ratings[1:5], type="ratings")
as(prediction, "matrix")[,1:5]

#Estimating RMSE
set.seed(1)

model <- Recommender(getData(e, "train"), method = "UBCF", 
                     param=list(normalize = "center", method="Cosine", nn=50))

prediction <- predict(model, getData(e, "known"), type="ratings")

rmse_ubcf <- calcPredictionAccuracy(prediction, getData(e, "unknown"))[1]
rmse_ubcf



```

# Item-Item Collaborative Filtering

```{r}
#Building model
model <- Recommender(real_ratings, method = "IBCF", 
                     param=list(normalize = "center", method="Cosine", k=350))

#Making predictions 
prediction <- predict(model, real_ratings[1:5], type="ratings")
as(prediction, "matrix")[,1:8]

#Estimating RMSE
set.seed(1)

model <- Recommender(getData(e, "train"), method = "IBCF", 
                     param=list(normalize = "center", method="Cosine", k=350))

prediction <- predict(model, getData(e, "known"), type="ratings")

rmse_ibcf <- calcPredictionAccuracy(prediction, getData(e, "unknown"))[1]
rmse_ibcf



```

# summary of findings and recommendations

Summary of findings and recommendations
Compare the RMSEs of content based model, user-user based model, and item-item based model, they are 0.9578232, 0.985047, 1.032426 respectively. The results show that the model accuracy from high to low is content based model, user-user based model, item-item based model. Generally speaking, the highest performance of these three models is item-item based model, and the content based is the lowest. It looks a conflict of the results with the general model performance.
I would consider to rerun the model at least 10 times to get a more accurate result.


# Reference:

Building a Recommendation System with R by Suresh K. Gorakala, Michele Usuelli

https://rpubs.com/tarashnot/recommender_comparison


